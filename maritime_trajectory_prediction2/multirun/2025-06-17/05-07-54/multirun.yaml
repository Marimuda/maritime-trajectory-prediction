hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
  launcher:
    _target_: hydra._internal.core_plugins.basic_launcher.BasicLauncher
  sweeper:
    _target_: hydra._internal.core_plugins.basic_sweeper.BasicSweeper
    max_batch_size: null
    params: null
  help:
    app_name: ${hydra.job.name}
    header: '${hydra.help.app_name} is powered by Hydra.

      '
    footer: 'Powered by Hydra (https://hydra.cc)

      Use --hydra-help to view Hydra specific help

      '
    template: '${hydra.help.header}

      == Configuration groups ==

      Compose your configuration from those groups (group=option)


      $APP_CONFIG_GROUPS


      == Config ==

      Override anything in the config (foo.bar=value)


      $CONFIG


      ${hydra.help.footer}

      '
  hydra_help:
    template: 'Hydra (${hydra.runtime.version})

      See https://hydra.cc for more info.


      == Flags ==

      $FLAGS_HELP


      == Configuration groups ==

      Compose your configuration from those groups (For example, append hydra/job_logging=disabled
      to command line)


      $HYDRA_CONFIG_GROUPS


      Use ''--cfg hydra'' to Show the Hydra config.

      '
    hydra_help: ???
  hydra_logging:
    version: 1
    formatters:
      simple:
        format: '[%(asctime)s][HYDRA] %(message)s'
    handlers:
      console:
        class: logging.StreamHandler
        formatter: simple
        stream: ext://sys.stdout
    root:
      level: INFO
      handlers:
      - console
    loggers:
      logging_example:
        level: DEBUG
    disable_existing_loggers: false
  job_logging:
    version: 1
    formatters:
      simple:
        format: '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'
    handlers:
      console:
        class: logging.StreamHandler
        formatter: simple
        stream: ext://sys.stdout
      file:
        class: logging.FileHandler
        formatter: simple
        filename: ${hydra.runtime.output_dir}/${hydra.job.name}.log
    root:
      level: INFO
      handlers:
      - console
      - file
    disable_existing_loggers: false
  env: {}
  mode: MULTIRUN
  searchpath: []
  callbacks: {}
  output_subdir: .hydra
  overrides:
    hydra:
    - hydra.mode=MULTIRUN
    task:
    - mode=train
    - experiment=traisformer_sweep
  job:
    name: main
    chdir: null
    override_dirname: experiment=traisformer_sweep,mode=train
    id: ???
    num: ???
    config_name: config
    env_set: {}
    env_copy: []
    config:
      override_dirname:
        kv_sep: '='
        item_sep: ','
        exclude_keys: []
  runtime:
    version: 1.3.2
    version_base: '1.3'
    cwd: /home/jakup/repo/maritime-trajectory-prediction/maritime_trajectory_prediction
    config_sources:
    - path: hydra.conf
      schema: pkg
      provider: hydra
    - path: /home/jakup/repo/maritime-trajectory-prediction/maritime_trajectory_prediction/configs
      schema: file
      provider: main
    - path: ''
      schema: structured
      provider: schema
    output_dir: ???
    choices:
      experiment: traisformer_sweep
      logger@experiment.logger: wandb
      callbacks@experiment.callbacks: default
      trainer@experiment.trainer: gpu
      model@experiment.model: traisformer
      data@experiment.data: ais_processed
      logger: wandb
      callbacks: default
      trainer: gpu
      model: traisformer
      data: ais_processed
      mode: train
      hydra/env: default
      hydra/callbacks: null
      hydra/job_logging: default
      hydra/hydra_logging: default
      hydra/hydra_help: default
      hydra/help: default
      hydra/sweeper: basic
      hydra/launcher: basic
      hydra/output: default
  verbose: false
seed: 42
data_dir: ${oc.env:MARITIME_DATA_DIR,data}
output_dir: ${oc.env:MARITIME_OUTPUT_DIR,outputs}
name: ${model.name}_experiment
wandb_project: maritime_trajectory_prediction
mode: train
train:
  auto_tune: false
  compile_model: false
  resume_from_checkpoint: null
  validate_every_n_epochs: 1
  save_predictions: false
  log_hyperparameters: true
  profiler: null
data:
  _target_: src.data.datamodule.AISFuserDataModule
  processed_dir: ${data_dir}/processed
  raw_dir: ${data_dir}/raw
  batch_size: 128
  num_workers: 8
  pin_memory: true
  sequence_length: 30
  prediction_horizon: 12
  validation_split: 0.2
  test_split: 0.1
  feature_columns:
  - lat
  - lon
  - sog
  - cog
  target_columns:
  - lat
  - lon
  - sog
  - cog
  normalize_features: true
  filter_outliers: true
  min_trajectory_length: 50
model:
  name: traisformer
  type: traisformer
  task: trajectory_prediction
  checkpoint_path: null
  _target_: src.models.traisformer.TrAISformer
  d_model: 768
  nhead: 8
  num_layers: 8
  dim_feedforward: 2048
  dropout: 0.1
  lat_bins: 250
  lon_bins: 270
  sog_bins: 30
  cog_bins: 72
  supports_anomaly_detection: false
  supports_uncertainty: true
trainer:
  accelerator: gpu
  devices: 1
  precision: 16-mixed
  max_epochs: 100
  learning_rate: 0.0001
  weight_decay: 0.01
  optimizer: adam
  scheduler: null
  check_val_every_n_epoch: 1
  val_check_interval: null
  log_every_n_steps: 50
  gradient_clip_val: 1.0
  benchmark: true
  compile: false
  deterministic: false
callbacks:
  early_stopping: true
  monitor: val/loss
  patience: 15
  mode: min
  checkpoint_dir: ${output_dir}/checkpoints
  save_top_k: 3
  save_last: true
  lr_logging_interval: epoch
  device_stats: true
  rich_progress: true
logger:
  type: wandb
  name: ${name}
  save_dir: ${output_dir}/logs
  version: null
  wandb_project: ${wandb_project}
  wandb_tags:
  - ${model.type}
  - ${mode}
  offline: false
  log_model: true
experiment:
  seed: 42
  name: ${model.name}_experiment
  data_dir: data/
  output_dir: outputs/${name}/
  data:
    _target_: src.data.datamodule.AISFuserDataModule
    processed_dir: ${data_dir}/processed
    raw_dir: ${data_dir}/raw
    batch_size: 128
    num_workers: 8
    pin_memory: true
    sequence_length: 30
    prediction_horizon: 12
    validation_split: 0.2
    test_split: 0.1
    feature_columns:
    - lat
    - lon
    - sog
    - cog
    target_columns:
    - lat
    - lon
    - sog
    - cog
    normalize_features: true
    filter_outliers: true
    min_trajectory_length: 50
  model:
    name: traisformer
    type: traisformer
    task: trajectory_prediction
    checkpoint_path: null
    _target_: src.models.traisformer.TrAISformer
    d_model: 768
    nhead: 8
    num_layers: 8
    dim_feedforward: 2048
    dropout: 0.1
    lat_bins: 250
    lon_bins: 270
    sog_bins: 30
    cog_bins: 72
    supports_anomaly_detection: false
    supports_uncertainty: true
  trainer:
    accelerator: gpu
    devices: 1
    precision: 16-mixed
    max_epochs: 100
    learning_rate: 0.0001
    weight_decay: 0.01
    optimizer: adam
    scheduler: null
    check_val_every_n_epoch: 1
    val_check_interval: null
    log_every_n_steps: 50
    gradient_clip_val: 1.0
    benchmark: true
    compile: false
    deterministic: false
  callbacks:
    early_stopping: true
    monitor: val/loss
    patience: 15
    mode: min
    checkpoint_dir: ${output_dir}/checkpoints
    save_top_k: 3
    save_last: true
    lr_logging_interval: epoch
    device_stats: true
    rich_progress: true
  logger:
    type: wandb
    name: ${name}
    save_dir: ${output_dir}/logs
    version: null
    wandb_project: ${wandb_project}
    wandb_tags:
    - ${model.type}
    - ${mode}
    offline: false
    log_model: true
  hydra:
    defaults:
    - override /sweeper: optuna
    sweeper:
      study_name: traisformer_optimization
      direction: minimize
      n_trials: 30
      sampler:
        _target_: optuna.samplers.TPESampler
        seed: ${seed}
      params:
        model.d_model: choice(256, 512, 768)
        model.nhead: choice(4, 8, 12)
        model.num_layers: choice(4, 6, 8)
        model.dim_feedforward: choice(1024, 2048, 4096)
        model.dropout: interval(0.0, 0.5)
        model.optimizer.lr: interval(1e-5, 1e-3)
        model.optimizer.weight_decay: interval(1e-6, 1e-3)
